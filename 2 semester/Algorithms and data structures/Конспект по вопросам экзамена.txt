1.1
Список смежности графа G с числом вершин V и рёбер E - это массив A[V], каждый элемент A[i] которого содержит список узлов смежных с вершиной i.
Память: O(V + E)      -  Так как хранит n списков для каждой вершины и суммарная длина списков равна кол-ву рёбер E.
Время доступа к ребру: O(E)        - Так как длина списка для конкретной вершины может достигать величину кол-ва рёбер.
Данный алгоритм эффективнее для разреженных графов, то есть когда  (V^2) >> E
1.2
Матрица смежности графа G с числом вершин V - это матрица A[V][V], каждый элемент A[i][j] которой равен числу рёбер из i-й вершины графа в j-ю.
Память: O(V^2)       - Так как хранит матрицу чисел, состоящую из n^2 элементов.
Время доступа к ребру: O(1)        - каждое ребро доступно по индексам её вершин за одну операцию.
Алгоритм наиболее эффективен для плотных графов, то есть когда E ~ (V^2)
1.3
Поиск в ширину на графе G с числом вершин V и рёбер E применяется чаще всего для поиска кратчайших путей от вершины u до всех других вершин.
Алгоритм поиска в ширину обходит ребра графа, пока не обойдёт все вершины, достижимые из u, вычисляя при этом расстояние (минимальное количество рёбер) от u до каждой вершины. С каждой итерацией он рассматривает непосещённые, смежные с текущей, вершины и ставит их в очередь, присваивая им в этот момент расстояние до вершины u.
Время работы алгоритма: O(V + E)        - Потому что мы проходим по каждому ребру, достижимому из u только 1 раз, а таких рёбер не больше E, и по каждой вершине, достижимой из u только 1 раз, отчего и получается такая асимптотика.
1.4
Диаметр дерева можно найти, запуская bfs сначала от первой вершины. Назовём её v1. Самая удалённая вершина от v1 будет называть v2. Далее запустим bfs уже от v2 и найдём самую удалённую от неё вершину - v3. Тогда путь между вершинами v2 и v3 будет диаметром этого графа.
Центр графа можно найти путём отбрасывания листьев дерева в текущем состоянии, пока не останется менее трёх вершин. Сделаем это так: сначала пройдёмся обходом в ширину по дереву и пометим все его листья числом 0, затем исключим эти вершины из графа и уже новые листья пометим числом 1, и так далее, пока не останутся 1 или 2 вершины, которые и будут являться центром этого дерева. А числа, записанные для каждой вершины будут иллюстрировать минимальное расстояние до листьев.

2.1
Поиск в глубину осуществляется путём рекурсивного вызова функции. Мы будем хранить массив, иллюстрирующий состояние вершины (посещённая или нет). Каждый раз мы из функции от вершины v рекурсивно вызываем функции от непосещённых соседей вершины v, но перед этим отмечаем, что вершина v уже посещена, чтобы не было зацикливаний.
Время работы обхода dfs:
Для списка смежности О(V + Е) - для каждой вершины просматриваем только рёбра, инцидентные ей, причём проходим по каждому ребру только 1 раз.
Для матрицы смежности O(V * V) - для каждой вершины поиск инцидентных ребер занимает V действий.
Для списка ребер (E * V) - должны рассмотреть для всех вершин инцидентные им ребра, для поиска таких необходимо пробегать по всему списку ребер.
2.2
Чтобы найти цикл в неориентированном графе, нам понадобится дополнительный массив, который будет хранить состояние каждой вершины в текущем состоянии пробега dfs. Этот массив для вершины v хранит число 0 в том случае, если вершина ещё не была посещена в пробеге, число 1, если запуск функции с этой вершиной был осуществлён, но окончания работы функции ещё не было, и число 2, если вершина v уже обрабатывалась и обработка этой вершины была завершена. В таком случае, цикл мы сможем найти, когда найдём ребро из вершины с числом 1 в вершину с числом 1, т.к. рекурсивная цепь доказывает их связность с одной стороны, а найденное ребро - с другой стороны, то есть обнаружился цикл.
Для того, чтобы найти все компоненты связности графа, мы должны в цикле запускать обходы в глубину от тех вершин, которые до сих пор не были посещены, а затем присваивать всем вершинам нового обхода какое-то уникальное число, обозначающее их компоненту связности, для этого можно просто немного модифицировать dfs и учесть это присвоение в функции.
2.3
Топологическая сортировка находится при помощи записи моментов возврата функции из каждой вершины. Для этого мы можем обозначить целочисленную переменную time, и присвоить ей значение 0. Затем перед каждым возвратом функции в отдельном массиве будем записывать время выхода для каждой переменной. И те переменные, у которых время выхода больше, они должны стоять раньше в топологической сортировке, т.к. в момент возврата функции алгоритм гарантирует, что все достижимые вершины уже посещены и значение time у них будет меньше.
Но такой алгоритм не годится, т.к. в конце придётся сортировать все времена для сортировки вершин, так что можно упростить его, просто созданием массива вершин, в котором по порядку выхода будут появляться вершины, потом достаточно просто развернуть этот массив и получить более простую реализацию алгоритма.
Время работы алгоритма: O(V + E), т.к. кроме разворачивания массива никаких иных действий по поводу обхода в глубину не производится, а т.к. разворачивание массива займёт O(V) времени, то асимптотика ничем не отличается от асимптотики dfs.
2.4
Конденсация графа это граф, вершинами которого являются компоненты сильной связности в исходном графе, а ребро между вершинами существует, только если существует ребро между какими-то двумя вершинами из этих компонент.
Компоненты сильной связности можно найти при помощи топологической сортировки вершин графа и построении инвертированного нашему графа. На инвертированном графе (графе, у которого все рёбра смотрят в другую сторону) от каждой вершины, для которой ещё не определена компонента сильной связности, в порядке топологической сортировки запускаем dfs. Все вершины, достижимые обходом в глубину, принадлежат той же компоненте сильной связности.
Время работы алгоритма: O(V + E), т.к. все используемые алгоритмы ограничены такой асимптотикой.
2.5
Алгоритм Крускала предназначен для поиска минимального остовного дерева для взвешенного связного неорграфа.
Идём по возрастанию весов рёбер и добавляем их в новый изначально пустой граф так, чтобы не образовывался цикл. В итоге мы получим MST. Для реализации оптимального алгоритма необходимо будет использовать снм на вершинах графа.
Время работы алгоритма: O((E * log(E) + V * log(V)), так как необходимо отсортировать все рёбра за O(E * log(E)), а потом объединять системы множеств вершин за O(E + V * log(V)).
2.6
Алгоритм Прима предназначен для поиска минимального остовного дерева для взвешенного связного неорграфа.
Алгоритм за O(V^2) для плотных графов: для каждой ещё не выбранной вершины будем хранить минимальное ребро, ведущее в уже выбранную вершину. Далее просто (V-1) раз добавляем вершины с наименьшим минимальным рёбром в остов. Изменение всех других вершин будет происходить за V операций, т.к. мы просто будем изменять наименьшее входящее ребро для каждой вершины в меньшую сторону или не изменять его.
Алгоритм за O(E * log(V)) для не таких уж и плотных графов: Будем хранить приоритетную очередь для всех минимальных рёбер вершин. Релаксацию (действие с минимальным ребром вершины) будем производить для всех соседей только что добавленной вершины. Так как изъятие вершины из кучи будет происходить за log(V), а изъятие всех вершин, соответственно, V * log(V), а релаксация каждого соседа за log(V) и переходов к соседям O(E), то суммарная асимптотика равна O((V + E) * log(V)), ну а т.к. граф связный, то E не меньше, чем V - 1, то есть общая асимптотика составляет O(E * log(V)).

3.1
Алгоритм Беллмана-Форда находит кратчайшие пути до всех вершин из заданной вершины v и сообщает о циклах отрицательного веса.
Заводим массив расстояний, в котором d[v] = 0, а остальные элементы равны бесконечности.
V - 1 раз просматриваем все ребра и пытаемся сделать релаксацию (уменьшить значения массива d).
В конце производим еще одну релаксацию, и если какой то элемент уменьшился, то в графе есть цикл отрицательного веса.
Лемма “свойство ослабления пути”: после V - 1 релаксаций всех ребер графа для всех вершин оценка расстояния будет равна длине кратчайшего пути из стартовой вершины v, если таковая существует.
Доказательство леммы: Рассмотрим путь из вершины v в u. В нем максимум может быть V вершин и V - 1 ребро. На первой итерации 100% корректно оценится путь до v1, на второй до v2 и так далее. Поэтому нам хватит V - 1 релаксаций.
Время работы алгоритма: O(V * E). Так как проводится V этапов по E релаксаций, то общая асимптотика, это O(V * E).
3.2
Поиск расстояний от вершины до всех остальных в ациклическом орграфе.
Применяем dfs от вершины v, поиск расстояний до которой и нужно осуществлять. Внутри функции перед переходом к соседям вершины будем обновлять её расстояние относительно предка, и по сути всё.
Время работы алгоритма: O(V + E).
3.3
Алгоритм Дейкстры с кучей осуществляется при помощи кучи, в которой хранятся расстояния до всех вершин. Сначала мы заносим в кучу самую первую вершину, затем выполняем алгоритм, пока куча не опустошится. Алгоритм заключается в выборе вершины с минимальным расстоянием и релаксацией всех её соседей, и тех, что релаксировали, нужно положить в кучу или обновить в ней расстояние.
Время работы алгоритма: O((V + E) * log(V)). Потому что общая релаксация всех соседей для вершин выполняется не больше, чем E раз и с асимптотикой O(log(V)). И изъятие минимальной вершины происходит V раз за O(log(V)), т.к. каждая вершина, изъятая из кучи, больше туда не попадает, ведь в куче остаются только те вершины, до которых кратчайшее расстояние больше, чем до изъятой вершины.
3.4
Алгоритм Дейкстры с массивом осуществляется при помощи массива, в котором хранятся расстояния до всех вершин и очереди, содержащей релаксированные необработанные вершины. Используется обычный bfs с очередью, где релаксируются все рёбра, направленные в соседей текущей вершины, но текущая вершина ищется перебором среди всех вершин, находящихся в очереди и изымается вершина, с самым минимальным расстоянием до неё.
Время работы алгоритма: O(E + V^2). Потому что все рёбра релаксируются за O(1), ведь хранятся в массиве. И минимальная вершина ищется O(V) раз за O(V).
3.5
Алгоритм Флойда находит расстояния между всеми парами вершин за O(V^3) по времени и O(V^2) по памяти. Работает корректно только для случаев без отрицательного цикла. Иначе выдаёт неправильный ответ для пары вершин, находящейся в отрицательном цикле.
Дан взвешенный ориентированный граф G(V,E), в котором вершины пронумерованы от 1 до n. Алгоритм Флойда заключается в том, чтобы добавлять по 1й вершине в множество рассматриваемых вспомогательных вершин для каждой пары вершин и обновлять через них расстояние. Для пустого множества составим матрицу расстояний из бесконечностей, где нет ориентированных рёбер и весов рёбер, где они есть. Далее предположим, что добавлено уже i вершин (с номерами от 1 до i) и через это множество для всех пар расстояния подсчитаны, тогда при добавлении вершины с номером (i+1) нам нужно перебрать все пары вершин u и v, чтобы в случае, если сумма расстояний через вершину (i+1) окажется меньше, уменьшить расстояние между ними.
Время работы алгоритма: O(V^3). Потому что мы добавляем в вспомогательное множество n вершин, и в добавлении каждой из них перебираем все пары вершин, выходит, что асимптотика - V^3.
3.6
Беллмана-Форда  -  расстояние от одной до всех  -  любой орграф, даже с циклами отриц. веса  -  O(V * E)
Поиск кратчайших в ациклическом орграфе  -  расстояние от одной до всех  -  ориентированный и ациклический  -  O(V + E)
Дейкстра с кучей  -  расстояние от одной до всех  -  неотрицательные веса рёбер  -  O(E * log(V))
Дейкстра с массивом  -  расстояние от одной до всех  -  неотрицательные веса рёбер  -  O(V^2)
Флойд-Уоршелл  -  расстояние между всеми парами  -  любой граф без отрицательных циклов  -  O(V^3)

4.1
i-е число Фибоначчи можно найти при помощи рекурсивных функций, вызывая каждый раз 2 новых функции из рекурсивного соотношения. Но тогда число вызовов функции и, соответственно, время работы программы будут сопоставимы с самим числом Фибоначчи, и у нас не получится вычислить даже 100е число. Соответственно, программу нужно ускорять при помощи мемоизации, то есть сохранения вызовов функции. Это можно сделать простым методом, предварительным созданием массива длины i из элементов, равных -1. Далее перед выходом из функции присваивать элементу в массиве его значение числа Фибоначчи, а сразу после вызова функции проверять, было ли уже подсчитано текущее число Фибоначчи, если да, то сразу возвращать его. Тогда программа будет работать за O(i), т.к. для каждого числа от 1 до i, дальнейший рекурсивный запуск будет выполняться не больше 2 раз, то есть суммарный запуск рекурсии не превысит 2n раз.
4.2
У нас есть n грузов, где i-й груз имеет массу A[i], и рюкзак, вместимостью x, нужно найти максимальную массу грузов, которую мы можем поместить в рюкзак. Решение должно быть за O(x * n).
Решение заключается в том, что ответ не может превысить x. Соответственно, для всех чисел от 1 до x будем хранить значение 1 или 0, в зависимости от того, можно ли составить такую массу из данных грузов или нет. Изначально для нулевой массы будем хранить значение 1. Потом будем постепенно прибавлять новые грузы и обновлять ответы для всех масс. То есть нам нужно будем n раз пробежаться по числам от 1 до х, оттуда и такая асимптотика.
4.3
Нахождение наибольшей возрастающей подпоследовательности за квадратичное время осуществляется сохранением ответов для всех префиксов. Далее просто в переходе обращаемся ко всем предыдущим ответам, и ищем самую большую подходящую подпоследовательность, оканчивающуюся на число, меньшее того, которое мы хотим добавить. Далее мы её переписываем и добавляем туда наш новый элемент.
Алгоритм работает за O(n^2), т.к. для каждого массива можно хранить его размер, и тогда поиск самого длинного подходящего массива будет осуществляться за O(n), а также копирование и добавление нового элемента в массив, тоже за O(n). И так n раз, поэтому O(n^2).
В варианте с логарифмом будем хранить массив из n элементов, где для i-го элемента хранится адрес минимального элемента в исходной последовательности, на который заканчивается возрастающая подпоследовательность длины i. Так же для восстановления ответа необходимо хранить предков для каждого числа последовательности, то есть то самое число, на которое заканчивается лучшая предыдущая подпоследовательность.
Алгоритм работает за O(n * log(n)). Так как мы n раз ищем такую максимальную длину подпоследовательности, чтобы она была заканчивалась на число меньшее, чем новое. Это ищется бинпоиском за O(log(n)).
4.4
Задача о порядке перемножения матриц — классическая задача динамического программирования, в которой дана последовательность матриц A1, A2, ... , A_n и требуется минимизировать количество скалярных операций для вычисления их произведения. Матрицы предполагаются совместимыми по отношению к матричному умножению (то есть количество столбцов A_i-1 совпадает с количеством строк A_i матрицы). По сути нам просто нужно расставить скобки на последовательности матриц, которые зададут оптимальный порядок их перемножения.
Решение: будем хранить результаты произведений целых отрезков матриц. Для нахождения нового отрезка нужно обратиться ко всевозможным его дроблением на 2 других отрезка, результаты которых мы сложим с перемножением этих отрезков, после чего присвоим минимум из всех таких дроблений новому отрезку.
Решение работает за O(n^3), так как у нас есть O(n^2) всевозможных отрезков матрицы и мы для каждого такого отрезка делаем O(n) дроблений для поиска результата.
4.5
if(A[l] == A[r]) DP[l][r] = DP[l+1][r] + DP[l][r-1] + 1   // из-за равенства этих элементов все элементы отрезка от l+1 до r-1 должны сосчитаться повторно. А единица берётся как подпалиндром всего из двух элементов (l и r).
else DP[l][r] = DP[l+1][r] + DP[l][r-1] - DP[l+1][r-1]    // так как надо посчитать все палиндромы от l до r-1 и добавить r-й элемент 
(ещё + DP[l+1][r] - DP[l+1][r-1] уникальных палиндромов).
4.6
Максимальное независимое число вершин в дереве ищется с помощью ДП. Для каждой вершины будем сохранять ответ для всего поддерева. Причём сохраняем 2 ответа: с включением этой вершины и без включения.
5.1
Полиномиальный хеш строки - значение полиномиальной хеш-функции от строки по модулю k. Хеш-функция берёт взаимнопростое с k число и суммирует порядковые степени этого числа с коэффициентами, равными кодам элементов строки.
hash(P) = (p0 * x ^ (m - 1) + p1 * x ^ (m - 2) + … + p(m-2) * x + p(m-1)) mod k
Итеративное вычисление: hash(P + С) = (p0 * x ^ m + p1 * x ^ (m - 1) + … + p(m-2) * x ^ 2 + p(m-1) * х + С) mod k = (hash(P) * x + C) mod k
Пересчет при сдвиге:
Hi = hash(T[i … i + m - 1]) 
Hi = (ti * x ^ (m - 1) + t(i + 1) * x ^ (m - 2) + t(i + m - 1)) mod k
H(i + 1) = hash(T[i + 1 … i + m]) 
H(i + 1) = (t(i + 1) * x ^ (m - 1) + t(i + 2) * x ^ (m - 2) + t(i + m)) mod k = (Hi * x - ti * x ^ m + t(i + m)) mod k

